{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "cd2f8b29-bc78-4a94-b85c-8ebb1626ae00",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Matplotlib is building the font cache; this may take a moment.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class AnimalClassifier:\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "        self.X_train, self.X_test, self.y_train, self.y_test = None, None, None, None\n",
        "        self.rf_model, self.knn_model = None, None\n",
        "        self.rf_predictions, self.knn_predictions = None, None\n",
        "        self.results = {}\n",
        "    \n",
        "    def omega_train_and_evaluate(self):\n",
        "        \"\"\"Comprehensive model training and evaluation\"\"\"\n",
        "        # Part A: Prepare data and split\n",
        "        self._prepare_and_split_data()\n",
        "        \n",
        "        # Part B: Configure and train Random Forest\n",
        "        self._train_random_forest()\n",
        "        \n",
        "        # Part C: Print training performance\n",
        "        self._evaluate_performance()\n",
        "        \n",
        "        # Part D: Classification report\n",
        "        self._generate_classification_report()\n",
        "        \n",
        "        # Part E: Annotated confusion matrix heatmap (modified)\n",
        "        self._plot_confusion_matrix_no_seaborn()\n",
        "        \n",
        "        # Part F: Feature importance plot\n",
        "        self._plot_feature_importance_no_seaborn()\n",
        "        \n",
        "        # Part G: Comparison model - K-Nearest Neighbors\n",
        "        self._train_knn()\n",
        "        \n",
        "        # Part H: Critical analysis output\n",
        "        return self._generate_critical_analysis()\n",
        "    \n",
        "    def _prepare_and_split_data(self):\n",
        "        \"\"\"Prepare data and split into train/test sets\"\"\"\n",
        "        # Create a copy of the data\n",
        "        df = self.data.copy()\n",
        "        \n",
        "        # Select features - exclude non-predictive columns\n",
        "        exclude_columns = ['animal_name', 'animal_name_normalized', 'class_type_info', 'class_number_info']\n",
        "        feature_columns = [col for col in df.columns if col not in exclude_columns and col != 'class_type']\n",
        "        \n",
        "        # Handle categorical variables\n",
        "        categorical_columns = df[feature_columns].select_dtypes(include=['object']).columns\n",
        "        for col in categorical_columns:\n",
        "            le = LabelEncoder()\n",
        "            df[col] = le.fit_transform(df[col].astype(str))\n",
        "        \n",
        "        # Prepare X and y\n",
        "        X = df[feature_columns]\n",
        "        y = df['class_type']\n",
        "        \n",
        "        # Part A: Split data (75% train, 25% test, random_state=123)\n",
        "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
        "            X, y, test_size=0.25, random_state=123, stratify=y\n",
        "        )\n",
        "        \n",
        "        print(\"Data preparation completed:\")\n",
        "        print(f\"Training set: {self.X_train.shape[0]} samples\")\n",
        "        print(f\"Testing set: {self.X_test.shape[0]} samples\")\n",
        "        print(f\"Number of features: {self.X_train.shape[1]}\")\n",
        "    \n",
        "    def _train_random_forest(self):\n",
        "        \"\"\"Configure and train Random Forest model\"\"\"\n",
        "        # Part B: Configure Random Forest with specified parameters\n",
        "        self.rf_model = RandomForestClassifier(\n",
        "            n_estimators=150,\n",
        "            max_depth=15,\n",
        "            min_samples_split=2,\n",
        "            random_state=123\n",
        "        )\n",
        "        \n",
        "        self.rf_model.fit(self.X_train, self.y_train)\n",
        "        \n",
        "        # Make predictions\n",
        "        self.rf_train_predictions = self.rf_model.predict(self.X_train)\n",
        "        self.rf_test_predictions = self.rf_model.predict(self.X_test)\n",
        "        \n",
        "        print(\"Random Forest training completed\")\n",
        "    \n",
        "    def _evaluate_performance(self):\n",
        "        \"\"\"Evaluate model performance\"\"\"\n",
        "        # Part C: Calculate accuracies\n",
        "        rf_train_accuracy = accuracy_score(self.y_train, self.rf_train_predictions)\n",
        "        rf_test_accuracy = accuracy_score(self.y_test, self.rf_test_predictions)\n",
        "        overfitting_gap = rf_train_accuracy - rf_test_accuracy\n",
        "        \n",
        "        print(\"\\n=== RANDOM FOREST PERFORMANCE ===\")\n",
        "        print(f\"Training Accuracy: {rf_train_accuracy:.4f}\")\n",
        "        print(f\"Testing Accuracy: {rf_test_accuracy:.4f}\")\n",
        "        print(f\"Overfitting Gap: {overfitting_gap:.4f}\")\n",
        "        \n",
        "        self.results['rf_train_accuracy'] = rf_train_accuracy\n",
        "        self.results['rf_test_accuracy'] = rf_test_accuracy\n",
        "        self.results['overfitting_gap'] = overfitting_gap\n",
        "    \n",
        "    def _generate_classification_report(self):\n",
        "        \"\"\"Generate detailed classification report\"\"\"\n",
        "        # Part D: Classification report\n",
        "        print(\"\\n=== CLASSIFICATION REPORT (Random Forest) ===\")\n",
        "        class_report = classification_report(self.y_test, self.rf_test_predictions, output_dict=True)\n",
        "        print(classification_report(self.y_test, self.rf_test_predictions))\n",
        "        \n",
        "        # Store class-wise performance for analysis\n",
        "        class_performance = {}\n",
        "        for class_label, metrics in class_report.items():\n",
        "            if class_label not in ['accuracy', 'macro avg', 'weighted avg']:\n",
        "                class_performance[class_label] = {\n",
        "                    'precision': metrics['precision'],\n",
        "                    'recall': metrics['recall'],\n",
        "                    'f1': metrics['f1-score']\n",
        "                }\n",
        "        \n",
        "        self.results['class_report'] = class_report\n",
        "        self.results['class_performance'] = class_performance\n",
        "    \n",
        "    def _plot_confusion_matrix_no_seaborn(self):\n",
        "        \"\"\"Plot confusion matrix without seaborn\"\"\"\n",
        "        # Part E: Confusion matrix using matplotlib only\n",
        "        cm = confusion_matrix(self.y_test, self.rf_test_predictions)\n",
        "        \n",
        "        class_names = {\n",
        "            '1': 'Mammal', '2': 'Bird', '3': 'Reptile', \n",
        "            '4': 'Fish', '5': 'Amphibian', '6': 'Bug', '7': 'Invertebrate'\n",
        "        }\n",
        "        \n",
        "        labels = [class_names.get(str(i), f'Class {i}') for i in sorted(self.y_test.unique())]\n",
        "        \n",
        "        fig, ax = plt.subplots(figsize=(10, 8))\n",
        "        \n",
        "        # Create heatmap using imshow\n",
        "        im = ax.imshow(cm, cmap='Blues')\n",
        "        \n",
        "        # Add colorbar\n",
        "        cbar = ax.figure.colorbar(im, ax=ax)\n",
        "        cbar.ax.set_ylabel('Number of Predictions', rotation=-90, va=\"bottom\")\n",
        "        \n",
        "        # Set ticks and labels\n",
        "        ax.set_xticks(np.arange(len(labels)))\n",
        "        ax.set_yticks(np.arange(len(labels)))\n",
        "        ax.set_xticklabels(labels)\n",
        "        ax.set_yticklabels(labels)\n",
        "        \n",
        "        # Rotate x labels\n",
        "        plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
        "        \n",
        "        # Add text annotations\n",
        "        for i in range(len(labels)):\n",
        "            for j in range(len(labels)):\n",
        "                ax.text(j, i, cm[i, j], ha=\"center\", va=\"center\", color=\"black\")\n",
        "        \n",
        "        ax.set_title('Confusion Matrix - Random Forest\\n(n_estimators=150, max_depth=15, min_samples_split=2)', \n",
        "                    fontsize=14, fontweight='bold', pad=20)\n",
        "        ax.set_xlabel('Predicted Label', fontsize=12)\n",
        "        ax.set_ylabel('True Label', fontsize=12)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    \n",
        "    def _plot_feature_importance_no_seaborn(self):\n",
        "        \"\"\"Plot feature importance without seaborn\"\"\"\n",
        "        # Part F: Feature importance plot\n",
        "        feature_importance = self.rf_model.feature_importances_\n",
        "        feature_names = self.X_train.columns\n",
        "        \n",
        "        # Create DataFrame for sorting\n",
        "        importance_df = pd.DataFrame({\n",
        "            'feature': feature_names,\n",
        "            'importance': feature_importance\n",
        "        }).sort_values('importance', ascending=True)\n",
        "        \n",
        "        # Get top 12 features\n",
        "        top_12 = importance_df.tail(12)\n",
        "        \n",
        "        # Identify engineered features\n",
        "        engineered_features = ['predator_efficiency', 'habitat_mobility']\n",
        "        \n",
        "        plt.figure(figsize=(12, 8))\n",
        "        \n",
        "        # Create horizontal bar plot\n",
        "        colors = ['lightblue' if feat not in engineered_features else 'orange' \n",
        "                 for feat in top_12['feature']]\n",
        "        \n",
        "        y_pos = np.arange(len(top_12))\n",
        "        bars = plt.barh(y_pos, top_12['importance'], color=colors, alpha=0.7)\n",
        "        \n",
        "        # Add value labels on bars\n",
        "        for i, bar in enumerate(bars):\n",
        "            width = bar.get_width()\n",
        "            plt.text(width + 0.001, bar.get_y() + bar.get_height()/2, \n",
        "                    f'{width:.3f}', ha='left', va='center', fontsize=9)\n",
        "        \n",
        "        plt.yticks(y_pos, top_12['feature'])\n",
        "        plt.xlabel('Feature Importance Score', fontsize=12)\n",
        "        plt.title('Top 12 Feature Importances - Random Forest\\n(Engineered Features in Orange)', \n",
        "                 fontsize=14, fontweight='bold', pad=20)\n",
        "        plt.grid(axis='x', alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        self.results['feature_importance'] = importance_df\n",
        "        self.results['top_features'] = top_12\n",
        "    \n",
        "    def _train_knn(self):\n",
        "        \"\"\"Train K-Nearest Neighbors comparison model\"\"\"\n",
        "        # Part G: Train KNN model with k=5\n",
        "        # Scale features for KNN\n",
        "        scaler = StandardScaler()\n",
        "        X_train_scaled = scaler.fit_transform(self.X_train)\n",
        "        X_test_scaled = scaler.transform(self.X_test)\n",
        "        \n",
        "        self.knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "        self.knn_model.fit(X_train_scaled, self.y_train)\n",
        "        \n",
        "        # Make predictions\n",
        "        self.knn_predictions = self.knn_model.predict(X_test_scaled)\n",
        "        knn_accuracy = accuracy_score(self.y_test, self.knn_predictions)\n",
        "        \n",
        "        print(f\"\\n=== K-NEAREST NEIGHBORS PERFORMANCE ===\")\n",
        "        print(f\"KNN Testing Accuracy (k=5): {knn_accuracy:.4f}\")\n",
        "        \n",
        "        self.results['knn_accuracy'] = knn_accuracy\n",
        "    \n",
        "    def _generate_critical_analysis(self):\n",
        "        \"\"\"Generate critical analysis output\"\"\"\n",
        "        # Part H: Critical analysis\n",
        "        analysis = []\n",
        "        analysis.append(\"\\n\" + \"=\"*50)\n",
        "        analysis.append(\"CRITICAL MODEL ANALYSIS\")\n",
        "        analysis.append(\"=\"*50)\n",
        "        \n",
        "        # 1. Most important feature\n",
        "        top_feature_row = self.results['feature_importance'].iloc[-1]\n",
        "        analysis.append(f\"1. Most important feature: '{top_feature_row['feature']}' (importance: {top_feature_row['importance']:.3f})\")\n",
        "        \n",
        "        # 2. Worst performing class\n",
        "        worst_class = None\n",
        "        worst_f1 = 1.0\n",
        "        for class_label, metrics in self.results['class_performance'].items():\n",
        "            if metrics['f1'] < worst_f1:\n",
        "                worst_f1 = metrics['f1']\n",
        "                worst_class = class_label\n",
        "        \n",
        "        class_names = {\n",
        "            '1': 'Mammal', '2': 'Bird', '3': 'Reptile', \n",
        "            '4': 'Fish', '5': 'Amphibian', '6': 'Bug', '7': 'Invertebrate'\n",
        "        }\n",
        "        worst_class_name = class_names.get(worst_class, f'Class {worst_class}')\n",
        "        analysis.append(f\"2. Worst performing class: {worst_class_name} (F1: {worst_f1:.3f})\")\n",
        "        \n",
        "        # 3. Best performing class\n",
        "        best_class = None\n",
        "        best_f1 = 0.0\n",
        "        for class_label, metrics in self.results['class_performance'].items():\n",
        "            if metrics['f1'] > best_f1:\n",
        "                best_f1 = metrics['f1']\n",
        "                best_class = class_label\n",
        "        \n",
        "        best_class_name = class_names.get(best_class, f'Class {best_class}')\n",
        "        analysis.append(f\"3. Best performing class: {best_class_name} (F1: {best_f1:.3f})\")\n",
        "        \n",
        "        # 4. Engineered feature ranking\n",
        "        engineered_features = ['predator_efficiency', 'habitat_mobility']\n",
        "        total_features = len(self.results['feature_importance'])\n",
        "        \n",
        "        for engineered_feat in engineered_features:\n",
        "            if engineered_feat in self.results['feature_importance']['feature'].values:\n",
        "                rank = total_features - self.results['feature_importance'][\n",
        "                    self.results['feature_importance']['feature'] == engineered_feat\n",
        "                ].index[0]\n",
        "                importance = self.results['feature_importance'][\n",
        "                    self.results['feature_importance']['feature'] == engineered_feat\n",
        "                ]['importance'].values[0]\n",
        "                analysis.append(f\"4. Your engineered feature '{engineered_feat}' ranked #{rank} (importance: {importance:.3f})\")\n",
        "        \n",
        "        # 5. Model comparison\n",
        "        analysis.append(f\"5. Model comparison: KNN (k=5) = {self.results['knn_accuracy']:.3f} vs RF = {self.results['rf_test_accuracy']:.3f}\")\n",
        "        \n",
        "        # Additional insights\n",
        "        analysis.append(\"\\nADDITIONAL INSIGHTS:\")\n",
        "        analysis.append(f\"• Random Forest outperforms KNN by {self.results['rf_test_accuracy'] - self.results['knn_accuracy']:.3f} accuracy points\")\n",
        "        analysis.append(f\"• Overfitting gap is {'acceptable' if self.results['overfitting_gap'] < 0.1 else 'concerning'}: {self.results['overfitting_gap']:.3f}\")\n",
        "        \n",
        "        if any(feat in self.results['top_features']['feature'].values for feat in engineered_features):\n",
        "            analysis.append(\"• Engineered features are among the top contributors to model performance\")\n",
        "        else:\n",
        "            analysis.append(\"• Engineered features have moderate impact on model performance\")\n",
        "        \n",
        "        analysis.append(\"=\"*50)\n",
        "        \n",
        "        return \"\\n\".join(analysis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1963a058-d05f-400c-91b5-9daf5713471c",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (Pyodide)",
      "language": "python",
      "name": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
